---
---
@article{traqid,
  author={Kathalkar, Om and Nilesh, Nitin and Chaudhari, Sachin and Namboodiri, Anoop},
  abbr={ICVGIP},
  Journal={15th Indian Conference on Computer Vision Graphics and Image Processing (ICVGIP)}, 
  title={TRAQID - Traffic-Related Air Quality Image Dataset}, 
  year={2024},
  month={Dec},
  abstract={Air quality estimation through sensor-based methods is widely used. Nevertheless, their frequent failures and maintenance challenges constrain the scalability of air pollution monitoring efforts. Recently, it has been demonstrated that air quality estimation can be done using image-based methods. These methods offer several advantages including ease of use, scalability, and low cost. However, the accuracy of these methods hinges significantly on the diversity and magnitude of the dataset utilized. The advancement of air quality estimation through image analysis has been limited due to the lack of available datasets. Addressing this gap, we present TRAQID - Traffic-Related Air Quality Image Dataset, a novel dataset capturing 26,678 front and rear images of traffic alongside co-located weather parameters, multiple levels of Particulate Matters (PM) and Air Quality Index (AQI) values. Spanning over multiple seasons, with over 70 hours of data collection in the twin cities of Hyderabad and Secunderabad, India, the TRAQID offers diverse day and night imagery amid unstructured traffic conditions, encompassing six AQI categories ranging from “Good” to “Severe”. State-of-the-art air quality estimation techniques, which were trained on a smaller and less-diverse dataset, showed poor results on the dataset presented in this paper. TRAQID models various uncertainty types, including seasonal changes, unstructured traffic patterns, and lighting conditions. The information from the two views (front and rear) of the traffic can be combined to improve the estimation performance in such challenging conditions. As such, the TRAQID serves as a benchmark for image-based air quality estimation tasks and AQI prediction, given its diversity and magnitude.},
  selected={true},
  pdf={https://dl.acm.org/doi/pdf/10.1145/3702250.3702260},
  website={https://github.com/omkathalkar/TRAQID-Traffic-Related-Air-Quality-Image-Dataset},
  preview={traqid.pdf}
  }


@article{10152272,
  author={Nilesh, Nitin and Patwardhan, Ishan and Narang, Jayati and Chaudhari, Sachin},
  abbr={WF-IoT},
  Journal={IEEE 8th World Forum on Internet of Things (WF-IoT)}, 
  title={IoT-based AQI Estimation using Image Processing and Learning Methods}, 
  year={2022},
  month={Oct},
  abstract={Air pollution is a concern to the health of all living beings. It is essential to check on the quality of air in the surroundings. This article presents an IoT-based real-time air quality index (AQI) estimation technique using images and weather sensors on Indian roads. A mixture of image features, i.e., traffic density, visibility, and sensor features, i.e., temperature and humidity, were used to predict the AQI. Object detection and localization-based Deep Learning (DL) method along with image processing techniques were used to extract image features while an Machine Learning (ML) model was trained on those features to estimate the AQI. In order to conduct this experiment, a dataset containing 5048 images along with co-located AQI values across different seasons was collected by driving on the roads of Hyderabad city in India. The experimental results report an overall accuracy of 82% for AQI prediction.},
  selected={true},
  pdf={https://ieeexplore.ieee.org/abstract/document/10152272},
  code={https://github.com/omi-kron/IoT-based-AQI-Estimation-using-Image-Processing-and-Learning-Methods},
  blog={https://medium.com/@kathalkarom47/revolutionising-air-quality-monitoring-a-new-approach-using-images-and-ai-63a12764892c},
  website={https://spcrc.iiit.ac.in/blog/posts/21_IoT_based_AQI_Estimation.html},
  note={Winner of the <a href="https://www.helsinki.fi/en/researchgroups/ficore/events-and-activities/environmental-sensing-project-competition-2022">Environmental Sensing Project Competition 2022</a>.},
  preview={AQI_Image.png}
  }

@article{10152160,
  abbr={WF-IoT},
  author={Nilesh, Nitin and Narang, Jayati and Parmar, Ayu and Chaudhari, Sachin},
  Journal={IEEE 8th World Forum on Internet of Things (WF-IoT)}, 
  title={IoT and ML-based AQI Estimation using Real-time Traffic Data}, 
  year={2022},
  abstract={This paper proposes an IoT and machine learning (ML)-based novel method to estimate the air quality index (AQI) using traffic data in real-time. With the help of particulate matter (PM) monitoring nodes deployed in fifteen locations with diverse traffic scenarios of Indian roads, and using digital map service providers, a rich traffic dataset with approximately 210,000 samples has been collected. Three different ML models, namely random forest (RF), support vector machine (SVM), and multi-layer perceptron (MLP), are trained on this dataset to predict the AQI category into five levels. The experimental results show an accuracy of 82.60% with the F1-score of 83.67% on the complete dataset. Apart from this, ML models were also trained on individual node datasets, and the behavior of AQI levels was observed.},
  month={Oct},
  pdf={https://ieeexplore.ieee.org/abstract/document/10152160},
  selected={false},
  website={https://spcrc.iiit.ac.in/blog/posts/20_IoT_and_ML_based_AQI_Estimation.html},
  preview={HERE_Maps_Pipeline.png}
  }

  @article{pbl2019,
  abbr={Arxiv},
  author={Nilesh, Nitin and Sharma, Tushar and Ghosh, Anurag and Jawahar, C.V.},
  Journal={Arxiv Preprint},
  title={Towards Real-Time Analysis of Broadcast Badminton Videos},
  year={2023},
  abstract={Analysis of player movements is a crucial subset of sports analysis. Existing player movement analysis methods use recorded videos after the match is over. In this work, we propose an end-to-end framework for player movement analysis for badminton matches on live broadcast match videos. We only use the visual inputs from the match and, unlike other approaches which use multi-modal sensor data, our approach uses only visual cues. We propose a method to calculate the on-court distance covered by both the players from the video feed of a live broadcast badminton match. To perform this analysis, we focus on the gameplay by removing replays and other redundant parts of the broadcast match. We then perform player tracking to identify and track the movements of both players in each frame. Finally, we calculate the distance covered by each player and the average speed with which they move on the court. We further show a heatmap of the areas covered by the player on the court which is useful for analyzing the gameplay of the player. Our proposed framework was successfully used to analyze live broadcast matches in real-time during the Premier Badminton League 2019 (PBL 2019), with commentators and broadcasters appreciating the utility.},
  month={Oct},
  ARXIV={2308.12199},
  selected={true},
  note={An end-to-end framework for real-time badminton analysis, tested live in <a href="https://www.pbl-india.com">Premier Badminton League (PBL)</a>. Find the live broadcast by Hotstar showing the analysis <a href="https://www.youtube.com/watch?v=9ySjokzwE9I">here</a>.},
  html={https://www.youtube.com/watch?v=9ySjokzwE9I},
  blog={https://blogs.iiit.ac.in/pbl},
  code={https://gitlab.com/nitin.nilesh/badminton-analysis-star},
  preview={pbl.gif}
  }


@article{9590384,
  abbr={FiCloud},
  author={Lall, Ayush Kumar and Khandelwal, Ansh and Bose, Rishikesh and Bawankar, Nilesh and Nilesh, Nitin and Dwivedi, Ayush and Chaudhari, Sachin},
  Journal={8th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={Making Analog Water Meter Smart using ML and IoT-based Low-Cost Retrofitting}, 
  year={2021},
  pdf={https://ieeexplore.ieee.org/abstract/document/9590384},
  abstract={This paper introduces an internet-of-things (IoT) based economic retrofitting setup for digitising the analog water meters to make them smart. The setup contains a Raspberry-Pi microcontroller and a Pi-camera mounted on top of the analog water meter to take its images. The captured images are then preprocessed to estimate readings using a machine learning (ML) model. The employed ML algorithm is trained on a rich dataset that includes digits from the images of water meters captured by the hardware setup for ten days. The readings are posted on a cloud server in real-time using Raspberry-Pi. High temporal resolution plots of flow rate and volume are generated to derive inferences. The collected data can be used for deriving water consumption patterns and fault detection for efficient water management.},
  month={Aug},
  preview={smart_water_meter_2021.png}
  }

@article{9910524,
  abbr={FiCloud},
  author={Lall, Ayush Kumar and Khandelwal, Ansh and Nilesh, Nitin and Chaudhari, Sachin},
  Journal={9th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={Improving IoT-based Smart Retrofit Model for Analog Water Meters using DL based Algorithm}, 
  year={2022},
  abstract={This paper proposes a deep learning (DL)-based algorithm which is used for improving the performance of digit detection from internet-of-things (IoT)-based analog water meters. The DL algorithm is trained on a rich dataset of over 160,000 images collected from six water nodes deployed at locations with different environmental conditions. A detailed comparison between the proposed DL and machine learning (ML) algorithm is made based on detection accuracy, feature analysis, error analysis, and computational complexity analysis. It is observed that compared to the ML model, the proposed DL model maintained a higher detection accuracy and is more generalized in terms of feature extraction, which makes the algorithm robust.},
  month={Aug},
  pdf={https://ieeexplore.ieee.org/abstract/document/9910524},
  preview={Pipeline.pdf}
  }

@article{9910543,
  abbr={FiCloud},
  author={Viswanadh, K. S. and Kathalkar, Om and Vinzey, Piyusha and Nilesh, Nitin and Chaudhari, Sachin and Choppella, Venkatesh},
  Journal={9th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={CV and IoT-based Remote Triggered Labs: Use Case of Conservation of Mechanical Energy}, 
  year={2022},
  abstract={Remote Triggered Labs (RTL) are helpful for students to work on laboratory experiments virtually anytime, anywhere. Such setups can facilitate distance learning and are helpful during pandemics. In this paper, the use of Computer Vision (CV) is demonstrated for RTL experiments. For this, a use-case of the Conservation of Mechanical Energy experiment is considered. A CV-based approach is used to estimate an object’s velocity whose setup primarily consists of a microprocessor, a camera and infrared (IR) sensors. The experiment is recorded, and various CV techniques are employed to estimate the object’s velocity. This paper also compares a CV-based and an IR sensor-based approach to estimate the object’s velocity. Linear regression applied to the CV-based implementation resulted in an optimal mean-squared error (MSE), nearly 10 times better than IR-based implementation.},
  month={Aug},
  pdf={https://ieeexplore.ieee.org/abstract/document/9910543},
  preview={remote_labs_2022.pdf},
  blog={https://blogs.iiit.ac.in/rtl/},
  website={https://remote-labs.in}
  }

@article{doa2023,
  abbr={PIMRC},
  author={Khandelwal, Jigyasu and Latha, M. Madhuri and Nilesh, Nitin and Chaudhari, Sachin},
  Journal={34th Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)},
  title={DoA Estimation using Cascaded Neural Networks and Angle Classification for Coherent Signals},
  year={2023},
  abstract={This paper focuses on the direction of arrival (DoA) estimation for two coherent sources using a uniform linear array (ULA). It is demonstrated that the DoA estimation error increases as the angle of the incoming signal moves away from the center in the range (-90°, 90°) for existing schemes. In addition, this paper also focuses on improving the DoA estimation performance in low signal to noise ratio (SNR). Therefore a cascaded neural network (CaNN) is proposed to improve the DoA estimation consisting of two stages of neural networks (NNs). The first NN is the enhanced SNR (ESNR) classifier, which is used to improve performance for different SNRs. The second NN is the angle estimator, which improves the performance for different angle ranges. For overcoming the issue of coherent signals, a spatially smoothened auto covariance matrix is fed to the SNR classifier and angle estimator blocks. A performance comparison with an existing scheme such as spatial smoothing- multiple signal classification (SS-MUSIC) and ESNR CaNN shows that the proposed CaNN for different angles and SNR ranges performs better than the existing schemes.},
  month={Sep},
  preview={doa_pimrc.png},
  pdf={https://ieeexplore.ieee.org/abstract/document/10293904}
  }

  @article{remote_labs_v2,
  abbr={FiCloud},
  author={Das, Animesh and Viswanadh, K. S. and Agrawal, Rishabh and Gureja, Akshit and Nilesh, Nitin and Chaudhari, Sachin},
  Journal={10th International Conference on Future Internet of Things and Cloud (FiCloud)},
  title={Using Miniature Setups and Partial Streams for Scalable Remote Labs},
  year={2023},
  abstract={Remote labs allow students from anywhere in the world to access and conduct experiments without the need to physically be present in a lab at anytime. This is extremely important for students with little to no access to proper science labs because of a lack of infrastructure or a pandemic. There is a potential for scaling up the process so that queue delay can be removed and people are able to access dedicated experiment setups. This paper proposes a way for cost-effective scaling of Remote Labs by miniaturization of setups, image processing techniques, and partial streaming (using single camera to stream multiple experiments). For this, a use-case of the Vanishing Glass Rods experiment is considered. An end-to-end remote lab is created, including hardware setups and a dashboard to demonstrate the efficacy of the proposed approach in comparison to the existing approach of using lab-scale setups and one camera per experiment.},
  month={Aug},
  preview={Software_SplitScreen_Single_Updated.png},
  pdf={https://ieeexplore.ieee.org/abstract/document/10410768}
  }